{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del conjunto de entrenamiento: (60000, 28, 28)\n",
      "Forma del conjunto de prueba: (10000, 28, 28)\n",
      "Cantidad de instancias de entrenamiento: 60000\n",
      "Cantidad de instancias de prueba: 10000\n",
      "Dimensiones de las imágenes: (28, 28)\n",
      "Tipo de dato de las imágenes: uint8\n",
      "Tipo de dato de las etiquetas: uint8\n",
      "Etiquetas únicas en el conjunto de entrenamiento: [0 1 2 3 4 5 6 7 8 9]\n",
      "Etiquetas únicas en el conjunto de prueba: [0 1 2 3 4 5 6 7 8 9]\n",
      "Valor mínimo en las imágenes de entrenamiento: 0\n",
      "Valor máximo en las imágenes de entrenamiento: 255\n",
      "Valor promedio en las imágenes de entrenamiento: 72.94035223214286\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGxCAYAAADLfglZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmaUlEQVR4nO3df3DU9Z3H8dcmJEuAzdoAyW4kDakGtcJ5BSwhRX6dRHJ3VsRWWnt35HoyUoEZhjK9IueYO2+I9UbGucFqa+/40dPK3Rx6OlptTgjYBtpgUaNyHAhINAmBFBJIwoYkn/uDYc8Qfn0+Jvnkx/MxszNm833l+8nXb/Lim919b8AYYwQAgAcJvhcAABi8KCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCH0exs2bFAgELjkraysLL7tmjVr9NJLL3X5GmVlZV229enDDz9UcXGxDh8+3Gv7/N3vfqc77rhDoVBII0aM0KxZs/Sb3/ym1/aPwYkSwoCxfv167dy5s8tt4sSJ8W0uVUITJ07ssq1PH374of7+7/++10qooqJC06dPV0tLi37+85/r5z//uc6cOaM/+ZM/0c6dO3tlDRichvheANBdxo8fr8mTJztlU1NTlZeX180r6j8efvhhXXPNNXr99dc1bNgwSdLtt9+uL33pS1q5ciVXROgxXAlh0AgEAmpqatLGjRvjf6qbOXOmpEv/OW7Dhg264YYbFAwGddNNN2nTpk0qKirS2LFj49tcKnv48GEFAgFt2LCh0/27d+/W17/+daWlpWno0KH6yle+on//93/vtM9vfvObkqRZs2bF13r+65SWluquu+7SmDFjNHToUF1//fV64IEHdPz4cedj85vf/EYzZ86MF5AkhUIhTZ8+XeXl5aqpqXH+2sDlcCWEAaO9vV1tbW2d7gsEAkpMTJQk7dy5U7Nnz9asWbP08MMPSzp3BXQpGzZs0F//9V/rrrvu0hNPPKGGhgYVFxcrFospIcHt32/btm3T3LlzNWXKFD3zzDMKh8N64YUXtGDBAjU3N6uoqEh/9md/pjVr1uihhx7SU089Ff8T4XXXXSdJ+uijjzR16lTdf//9CofDOnz4sNauXatp06apsrJSSUlJnb7/GTNmXPGxrtbWVgWDwS73n7+vsrJS0WjU6XsGLocSwoBxsT+nJSYmxospLy9PCQkJGj169BX/9NbR0aHVq1dr4sSJevHFFxUIBCRJ06ZNU25urjIzM53W+OCDD+rmm2/W1q1bNWTIuR+/O+64Q8ePH9dDDz2kv/qrv9Lo0aOVm5srSfryl7/cZa2LFy+O/7cxRvn5+Zo5c6ays7P1y1/+Ul//+tc7ff/nS/hyvvzlL2vXrl3q6OiIF2xbW5t++9vfSpLq6+udvl/gSvhzHAaMTZs2qaKiotPt/C9RW/v27VN1dbXuu+++eAFJUnZ2tvLz852+5oEDB/Q///M/+s53viPp3C/587c//dM/VU1Njfbt23fFr1NXV6fFixcrKytLQ4YMUVJSkrKzsyVJe/fu7bRtW1ub3nzzzSt+zWXLlul///d/tXTpUn366aeqqqrS4sWL9fHHH0uS85UfcCVcCWHAuOmmm5yfmHCh8//yj0QiXT4XiUScnrV29OhRSdLKlSu1cuXKi25zpcd1Ojo6VFBQoOrqaj388MOaMGGChg8fro6ODuXl5amlpcV6XZL03e9+V8eOHdM//uM/6umnn5YkTZ06VStXrtSPfvQjXXvttU5fF7gSSgi4iJEjR0qSamtru3zuwvuGDh0qSYrFYp3uv7BQRo0aJUlatWqV5s+ff9H93nDDDZdd1/vvv693331XGzZs0MKFC+P3Hzhw4LK5q/G3f/u3Wr58ufbv369QKKTs7Gw98MADGj58uCZNmvS5vz5wMZQQBpVgMHhVVws33HCDotGofvGLX2jFihXxP8l9/PHHKi8v7/SY0Plnyr333nu644474ve//PLLXb5mbm6u3n33Xa1Zs+aK65TUZa3n13Hhkwh+8pOfXPF7uhrBYFDjx4+XJB05ckSbN2/WokWLlJKS0i1fH7gQJYQB4/333+/y7Djp3LPKRo8eLUmaMGGCysrK9MorrygajSoUCl306iMhIUGPPvqo7r//ft19991atGiRTp48qeLi4i5/ootEIrr99ttVUlKiL3zhC8rOztabb76pLVu2dPm6P/nJT1RYWKg77rhDRUVFuvbaa/WHP/xBe/fu1e9//3v9x3/8hyTFi+CnP/2pQqGQhg4dqpycHN1444267rrr9MMf/lDGGKWlpemVV15RaWnpRY/JkCFDNGPGjCs+LvT+++/rP//zPzV58mQFg0G9++67euyxx5Sbm6tHH330slngczFAP7d+/Xoj6ZK3Z599Nr7tO++8Y772ta+ZYcOGGUlmxowZxhhjtm3bZiSZbdu2dfraP/vZz0xubq5JTk4248aNM//6r/9qFi5caLKzszttV1NTY77xjW+YtLQ0Ew6HzV/8xV+Y3bt3G0lm/fr1nbZ99913zb333mvS09NNUlKSiUQiZvbs2eaZZ57ptN2TTz5pcnJyTGJiYqev8+GHH5o5c+aYUChkvvCFL5hvfvOb5siRI0aSeeSRRzp9jc9+j5ezb98+M336dJOWlmaSk5PN9ddfb/7u7/7OnD59+opZ4PMIGGOMl/YD+qmioiKVlZX16lw3YKDieZcAAG8oIQCAN/w5DgDgDVdCAABvKCEAgDeUEADAmz73YtWOjg5VV1crFAp1GhwJAOgfjDE6deqUMjMzrzj8ts+VUHV1tbKysnwvAwDwOVVVVWnMmDGX3abP/TkuFAr5XgIAoBtcze/zHiuhH//4x8rJydHQoUM1adIkvfXWW1eV409wADAwXM3v8x4poc2bN2v58uVavXq19uzZo9tuu02FhYU6cuRIT+wOANBP9ciLVadMmaKJEyfG3xxLOveGY/PmzVNJSclls42NjQqHw929JABAL2toaFBqauplt+n2K6HW1la9/fbbKigo6HR/QUGBysvLu2wfi8XU2NjY6QYAGBy6vYSOHz+u9vZ2ZWRkdLo/IyPjou9SWVJSonA4HL/xzDgAGDx67IkJFz4gZYy56INUq1atUkNDQ/xWVVXVU0sCAPQx3f46oVGjRikxMbHLVU9dXV2XqyPp3NsJX/hWxQCAwaHbr4SSk5M1adKkLm83XFpaqvz8/O7eHQCgH+uRiQkrVqzQX/7lX2ry5MmaOnWqfvrTn+rIkSNavHhxT+wOANBP9UgJLViwQPX19fqHf/gH1dTUaPz48XrttdeUnZ3dE7sDAPRTfe5N7XidEAAMDF5eJwQAwNWihAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3gzxvQCgLwkEAtYZY0wPrKSrUChknZk2bZrTvn75y1865Wy5HO/ExETrTFtbm3Wmr3M5dq568hznSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvGGAKfAZCQn2/y5rb2+3zlx//fXWmfvvv98609LSYp2RpKamJuvMmTNnrDO/+93vrDO9OYzUZUioyznksp/ePA62Q2ONMero6LiqbbkSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvGGAKfIbtoEbJbYDp7NmzrTO33367deaTTz6xzkhSMBi0zgwbNsw6M2fOHOvMz372M+vM0aNHrTPSuUGctlzOBxcjRoxwyl3tYNHPam5udtrX1eBKCADgDSUEAPCm20uouLhYgUCg0y0SiXT3bgAAA0CPPCZ0880367//+7/jH7v8nR0AMPD1SAkNGTKEqx8AwBX1yGNC+/fvV2ZmpnJycvStb31LBw8evOS2sVhMjY2NnW4AgMGh20toypQp2rRpk9544w09++yzqq2tVX5+vurr6y+6fUlJicLhcPyWlZXV3UsCAPRR3V5ChYWFuueeezRhwgTdfvvtevXVVyVJGzduvOj2q1atUkNDQ/xWVVXV3UsCAPRRPf5i1eHDh2vChAnav3//RT8fDAadXhgHAOj/evx1QrFYTHv37lU0Gu3pXQEA+pluL6GVK1dq+/btOnTokH7729/qG9/4hhobG7Vw4cLu3hUAoJ/r9j/HffLJJ/r2t7+t48ePa/To0crLy9OuXbuUnZ3d3bsCAPRz3V5CL7zwQnd/SaDXtLa29sp+br31VuvM2LFjrTOuLxRPSLD/I8kbb7xhnfnKV75inXn88cetM7t377bOSFJlZaV1Zu/evdaZr371q9YZl3NIksrLy60zO3futNreGHPVL7dhdhwAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeNPjb2oH+BAIBJxyxhjrzJw5c6wzkydPts6cOnXKOjN8+HDrjCSNGzeuVzIVFRXWmQMHDlhnRowYYZ2RpKlTp1pn5s+fb505e/asdcbl2EnS/fffb52JxWJW27e1temtt966qm25EgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3AeMyNrgHNTY2KhwO+14GeojrdOve4vLjsGvXLuvM2LFjrTMuXI93W1ubdaa1tdVpX7bOnDljneno6HDa1+9//3vrjMuUb5fjPXfuXOuMJH3pS1+yzlx77bVO+2poaFBqauplt+FKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8GeJ7ARhc+ti83G5x4sQJ60w0GrXOtLS0WGeCwaB1RpKGDLH/1TBixAjrjMsw0pSUFOuM6wDT2267zTqTn59vnUlIsL8eSE9Pt85I0uuvv+6U6ylcCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCANwwwBT6nYcOGWWdcBla6ZJqbm60zktTQ0GCdqa+vt86MHTvWOuMyBDcQCFhnJLdj7nI+tLe3W2dch7JmZWU55XoKV0IAAG8oIQCAN9YltGPHDt15553KzMxUIBDQSy+91OnzxhgVFxcrMzNTKSkpmjlzpj744IPuWi8AYACxLqGmpibdcsstWrdu3UU///jjj2vt2rVat26dKioqFIlENGfOHJ06depzLxYAMLBYPzGhsLBQhYWFF/2cMUZPPvmkVq9erfnz50uSNm7cqIyMDD3//PN64IEHPt9qAQADSrc+JnTo0CHV1taqoKAgfl8wGNSMGTNUXl5+0UwsFlNjY2OnGwBgcOjWEqqtrZUkZWRkdLo/IyMj/rkLlZSUKBwOx2997emDAICe0yPPjrvwOfnGmEs+T3/VqlVqaGiI36qqqnpiSQCAPqhbX6waiUQknbsiikaj8fvr6uq6XB2dFwwGFQwGu3MZAIB+oluvhHJychSJRFRaWhq/r7W1Vdu3b1d+fn537goAMABYXwmdPn1aBw4ciH986NAhvfPOO0pLS9MXv/hFLV++XGvWrFFubq5yc3O1Zs0aDRs2TPfdd1+3LhwA0P9Zl9Du3bs1a9as+McrVqyQJC1cuFAbNmzQD37wA7W0tOjBBx/UiRMnNGXKFP3qV79SKBTqvlUDAAaEgHGZBtiDGhsbFQ6HfS8DPcRlkKTLEEmXgZCSNGLECOvMnj17rDMux6GlpcU64/p4a3V1tXXm6NGj1hmXP9O7DEp1GSoqScnJydYZlxfmu/zOc30Sl8s5/jd/8zdW27e3t2vPnj1qaGhQamrqZbdldhwAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC86dZ3VgWuxGVoe2JionXGdYr2ggULrDPn31HYxrFjx6wzKSkp1pmOjg7rjCQNHz7cOpOVlWWdaW1ttc64TAY/e/asdUaShgyx/xXp8v9p5MiR1pmnnnrKOiNJf/zHf2ydcTkOV4srIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhgGm6FUugxBdhly6ev/9960zsVjMOpOUlGSd6c1Brunp6daZM2fOWGfq6+utMy7HbujQodYZyW2Q64kTJ6wzn3zyiXXmvvvus85I0j/90z9ZZ3bt2uW0r6vBlRAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeDOoB5gGAgGnnMsgyYQE+753Wd/Zs2etMx0dHdYZV21tbb22Lxevvfaadaapqck609LSYp1JTk62zhhjrDOSdOzYMeuMy8+Fy2BRl3PcVW/9PLkcuz/6oz+yzkhSQ0ODU66ncCUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN4MmAGmLgMA29vbnfbV14dw9mXTp0+3ztxzzz3Wma997WvWGUlqbm62ztTX11tnXIaRDhli/+Pqeo67HAeXn8FgMGidcRl66jrI1eU4uHA5H06fPu20r/nz51tnXnnlFad9XQ2uhAAA3lBCAABvrEtox44duvPOO5WZmalAIKCXXnqp0+eLiooUCAQ63fLy8rprvQCAAcS6hJqamnTLLbdo3bp1l9xm7ty5qqmpid9c3igMADDwWT/SWVhYqMLCwstuEwwGFYlEnBcFABgceuQxobKyMqWnp2vcuHFatGiR6urqLrltLBZTY2NjpxsAYHDo9hIqLCzUc889p61bt+qJJ55QRUWFZs+erVgsdtHtS0pKFA6H47esrKzuXhIAoI/q9tcJLViwIP7f48eP1+TJk5Wdna1XX331os9PX7VqlVasWBH/uLGxkSICgEGix1+sGo1GlZ2drf3791/088Fg0OkFawCA/q/HXydUX1+vqqoqRaPRnt4VAKCfsb4SOn36tA4cOBD/+NChQ3rnnXeUlpamtLQ0FRcX65577lE0GtXhw4f10EMPadSoUbr77ru7deEAgP7PuoR2796tWbNmxT8+/3jOwoUL9fTTT6uyslKbNm3SyZMnFY1GNWvWLG3evFmhUKj7Vg0AGBACxnWyXw9pbGxUOBz2vYxul5aWZp3JzMy0zuTm5vbKfiS3QYjjxo2zzlzqmZWXk5Dg9pfms2fPWmdSUlKsM9XV1daZpKQk64zLYExJGjlypHWmtbXVOjNs2DDrTHl5uXVmxIgR1hnJbeBuR0eHdaahocE643I+SNLRo0etMzfddJPTvhoaGpSamnrZbZgdBwDwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG96/J1Ve0teXp515tFHH3Xa1+jRo60z11xzjXWmvb3dOpOYmGidOXnypHVGktra2qwzp06dss64TGcOBALWGUlqaWmxzrhMdb733nutM7t377bOuL6Fisvk8rFjxzrty9aECROsM67HoaqqyjrT3NxsnXGZxO46GTw7O9sp11O4EgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAb/rsANOEhASrIZT//M//bL2PaDRqnZHcBou6ZFwGIbpITk52yrl8Ty4DQl2Ew2GnnMtwx8cee8w643Icvve971lnqqurrTOSdObMGevMm2++aZ05ePCgdSY3N9c6M3LkSOuM5DY8NykpyTqTkGB/PXD27FnrjCQdO3bMKddTuBICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8CxhjjexGf1djYqHA4rO985ztWgzVdhkh+9NFH1hlJGjFiRK9kgsGgdcaFy8BFyW1IaFVVlXXGZQjn6NGjrTOS2yDJSCRinZk3b551ZujQodaZsWPHWmckt/N10qRJvZJx+X/kMojUdV+uA4Ft2Qx4/iyXn/e8vDyr7Ts6OvTpp5+qoaFBqampl92WKyEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8GaI7wVcyrFjx6wG7bkMxgyFQtYZSYrFYtYZl/W5DJF0GZ54pQGDl/KHP/zBOvPxxx9bZ1yOQ0tLi3VGks6cOWOdaWtrs868+OKL1pnKykrrjOsA07S0NOuMy5DQkydPWmfOnj1rnXH5fySdG8Rpy2VAqMt+XAeYuvyOGDdunNX2bW1t+vTTT69qW66EAADeUEIAAG+sSqikpES33nqrQqGQ0tPTNW/ePO3bt6/TNsYYFRcXKzMzUykpKZo5c6Y++OCDbl00AGBgsCqh7du3a8mSJdq1a5dKS0vV1tamgoICNTU1xbd5/PHHtXbtWq1bt04VFRWKRCKaM2eOTp061e2LBwD0b1ZPTHj99dc7fbx+/Xqlp6fr7bff1vTp02WM0ZNPPqnVq1dr/vz5kqSNGzcqIyNDzz//vB544IHuWzkAoN/7XI8JNTQ0SPr/Z9IcOnRItbW1KigoiG8TDAY1Y8YMlZeXX/RrxGIxNTY2droBAAYH5xIyxmjFihWaNm2axo8fL0mqra2VJGVkZHTaNiMjI/65C5WUlCgcDsdvWVlZrksCAPQzziW0dOlSvffee/rFL37R5XMXPn/dGHPJ57SvWrVKDQ0N8ZvL62kAAP2T04tVly1bppdfflk7duzQmDFj4vdHIhFJ566IotFo/P66urouV0fnBYNBBYNBl2UAAPo5qyshY4yWLl2qLVu2aOvWrcrJyen0+ZycHEUiEZWWlsbva21t1fbt25Wfn989KwYADBhWV0JLlizR888/r//6r/9SKBSKP84TDoeVkpKiQCCg5cuXa82aNcrNzVVubq7WrFmjYcOG6b777uuRbwAA0H9ZldDTTz8tSZo5c2an+9evX6+ioiJJ0g9+8AO1tLTowQcf1IkTJzRlyhT96le/cp7TBgAYuALGGON7EZ/V2NiocDisCRMmKDEx8apzzz77rPW+jh8/bp2RpOHDh1tnRo4caZ1xGe54+vRp64zLwEVJGjLE/iFFl0GNw4YNs864DD2V3I5FQoL983tcfuyuueYa68xnX0huw2UA7IkTJ6wzLo8Hu/zcugw9ldwGn7rsKyUlxTpz/jF4Wy6DT5977jmr7WOxmNatW6eGhoYrDkhmdhwAwBtKCADgDSUEAPCGEgIAeEMJAQC8oYQAAN5QQgAAbyghAIA3lBAAwBtKCADgDSUEAPCGEgIAeEMJAQC8cXpn1d5QWVlptf2WLVus9/Hd737XOiNJ1dXV1pmDBw9aZ86cOWOdcZke7TpF22Xyb3JysnXGZpr6ebFYzDojSe3t7dYZl4nYzc3N1pmamhrrjOuQfJfj4DJVvbfO8dbWVuuM5DbJ3iXjMnnbZcK3pC5vRno1jh49arW9zfHmSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvAkY1wmHPaSxsVHhcLhX9lVYWOiUW7lypXUmPT3dOnP8+HHrjMvwRJdhlZLbYFGXAaYugzFd1iZJgUDAOuPyI+QyNNYl43K8XfflcuxcuOzHdgDn5+FyzDs6OqwzkUjEOiNJ7733nnXm3nvvddpXQ0ODUlNTL7sNV0IAAG8oIQCAN5QQAMAbSggA4A0lBADwhhICAHhDCQEAvKGEAADeUEIAAG8oIQCAN5QQAMAbSggA4E2fHWAaCASsBhW6DADsTbNmzbLOlJSUWGdcBqW6DoxNSLD/N4zLYFGXAaauQ1ld1NXVWWdcfuw+/fRT64zrz8Xp06etM65DY225HLuzZ8867au5udk64/JzUVpaap3Zu3evdUaSysvLnXIuGGAKAOjTKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOBNnx1git5z4403OuVGjRplnTl58qR1ZsyYMdaZw4cPW2ckt0GXH330kdO+gIGOAaYAgD6NEgIAeGNVQiUlJbr11lsVCoWUnp6uefPmad++fZ22KSoqir8X0PlbXl5ety4aADAwWJXQ9u3btWTJEu3atUulpaVqa2tTQUGBmpqaOm03d+5c1dTUxG+vvfZaty4aADAwWL1l5euvv97p4/Xr1ys9PV1vv/22pk+fHr8/GAwqEol0zwoBAAPW53pMqKGhQZKUlpbW6f6ysjKlp6dr3LhxWrRo0WXf/jgWi6mxsbHTDQAwODiXkDFGK1as0LRp0zR+/Pj4/YWFhXruuee0detWPfHEE6qoqNDs2bMVi8Uu+nVKSkoUDofjt6ysLNclAQD6GefXCS1ZskSvvvqqfv3rX1/2dRw1NTXKzs7WCy+8oPnz53f5fCwW61RQjY2NFFEv43VC/4/XCQHd52peJ2T1mNB5y5Yt08svv6wdO3Zc8RdENBpVdna29u/ff9HPB4NBBYNBl2UAAPo5qxIyxmjZsmV68cUXVVZWppycnCtm6uvrVVVVpWg06rxIAMDAZPWY0JIlS/Rv//Zvev755xUKhVRbW6va2lq1tLRIkk6fPq2VK1dq586dOnz4sMrKynTnnXdq1KhRuvvuu3vkGwAA9F9WV0JPP/20JGnmzJmd7l+/fr2KioqUmJioyspKbdq0SSdPnlQ0GtWsWbO0efNmhUKhbls0AGBgsP5z3OWkpKTojTfe+FwLAgAMHkzRBgD0CKZoAwD6NEoIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3lBCAABvKCEAgDd9roSMMb6XAADoBlfz+7zPldCpU6d8LwEA0A2u5vd5wPSxS4+Ojg5VV1crFAopEAh0+lxjY6OysrJUVVWl1NRUTyv0j+NwDsfhHI7DORyHc/rCcTDG6NSpU8rMzFRCwuWvdYb00pquWkJCgsaMGXPZbVJTUwf1SXYex+EcjsM5HIdzOA7n+D4O4XD4qrbrc3+OAwAMHpQQAMCbflVCwWBQjzzyiILBoO+leMVxOIfjcA7H4RyOwzn97Tj0uScmAAAGj351JQQAGFgoIQCAN5QQAMAbSggA4A0lBADwpl+V0I9//GPl5ORo6NChmjRpkt566y3fS+pVxcXFCgQCnW6RSMT3snrcjh07dOeddyozM1OBQEAvvfRSp88bY1RcXKzMzEylpKRo5syZ+uCDD/wstgdd6TgUFRV1OT/y8vL8LLaHlJSU6NZbb1UoFFJ6errmzZunffv2ddpmMJwPV3Mc+sv50G9KaPPmzVq+fLlWr16tPXv26LbbblNhYaGOHDnie2m96uabb1ZNTU38VllZ6XtJPa6pqUm33HKL1q1bd9HPP/7441q7dq3WrVuniooKRSIRzZkzZ8ANw73ScZCkuXPndjo/XnvttV5cYc/bvn27lixZol27dqm0tFRtbW0qKChQU1NTfJvBcD5czXGQ+sn5YPqJr371q2bx4sWd7rvxxhvND3/4Q08r6n2PPPKIueWWW3wvwytJ5sUXX4x/3NHRYSKRiHnsscfi9505c8aEw2HzzDPPeFhh77jwOBhjzMKFC81dd93lZT2+1NXVGUlm+/btxpjBez5ceByM6T/nQ7+4EmptbdXbb7+tgoKCTvcXFBSovLzc06r82L9/vzIzM5WTk6NvfetbOnjwoO8leXXo0CHV1tZ2OjeCwaBmzJgx6M4NSSorK1N6errGjRunRYsWqa6uzveSelRDQ4MkKS0tTdLgPR8uPA7n9YfzoV+U0PHjx9Xe3q6MjIxO92dkZKi2ttbTqnrflClTtGnTJr3xxht69tlnVVtbq/z8fNXX1/temjfn//8P9nNDkgoLC/Xcc89p69ateuKJJ1RRUaHZs2crFov5XlqPMMZoxYoVmjZtmsaPHy9pcJ4PFzsOUv85H/rcWzlczoXvL2SM6XLfQFZYWBj/7wkTJmjq1Km67rrrtHHjRq1YscLjyvwb7OeGJC1YsCD+3+PHj9fkyZOVnZ2tV199VfPnz/e4sp6xdOlSvffee/r1r3/d5XOD6Xy41HHoL+dDv7gSGjVqlBITE7v8S6aurq7Lv3gGk+HDh2vChAnav3+/76V4c/7ZgZwbXUWjUWVnZw/I82PZsmV6+eWXtW3btk7vPzbYzodLHYeL6avnQ78ooeTkZE2aNEmlpaWd7i8tLVV+fr6nVfkXi8W0d+9eRaNR30vxJicnR5FIpNO50draqu3btw/qc0OS6uvrVVVVNaDOD2OMli5dqi1btmjr1q3Kycnp9PnBcj5c6ThcTJ89Hzw+KcLKCy+8YJKSksy//Mu/mA8//NAsX77cDB8+3Bw+fNj30nrN97//fVNWVmYOHjxodu3aZf78z//chEKhAX8MTp06Zfbs2WP27NljJJm1a9eaPXv2mI8//tgYY8xjjz1mwuGw2bJli6msrDTf/va3TTQaNY2NjZ5X3r0udxxOnTplvv/975vy8nJz6NAhs23bNjN16lRz7bXXDqjj8L3vfc+Ew2FTVlZmampq4rfm5ub4NoPhfLjScehP50O/KSFjjHnqqadMdna2SU5ONhMnTuz0dMTBYMGCBSYajZqkpCSTmZlp5s+fbz744APfy+px27ZtM5K63BYuXGiMOfe03EceecREIhETDAbN9OnTTWVlpd9F94DLHYfm5mZTUFBgRo8ebZKSkswXv/hFs3DhQnPkyBHfy+5WF/v+JZn169fHtxkM58OVjkN/Oh94PyEAgDf94jEhAMDARAkBALyhhAAA3lBCAABvKCEAgDeUEADAG0oIAOANJQQA8IYSAgB4QwkBALyhhAAA3vwfGkbmteXrVwwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paso 1: Cargar y analizar el dataset\n",
    "\n",
    "# Cargar el dataset Fashion MNIST\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Revisar la forma del dataset\n",
    "print(f\"Forma del conjunto de entrenamiento: {x_train.shape}\")\n",
    "print(f\"Forma del conjunto de prueba: {x_test.shape}\")\n",
    "\n",
    "# Número de columnas e instancias\n",
    "num_train_samples = x_train.shape[0]\n",
    "num_test_samples = x_test.shape[0]\n",
    "image_shape = x_train.shape[1:]  # Dimensiones de las imágenes\n",
    "\n",
    "print(f\"Cantidad de instancias de entrenamiento: {num_train_samples}\")\n",
    "print(f\"Cantidad de instancias de prueba: {num_test_samples}\")\n",
    "print(f\"Dimensiones de las imágenes: {image_shape}\")\n",
    "\n",
    "# Revisar los tipos de datos\n",
    "print(f\"Tipo de dato de las imágenes: {x_train.dtype}\")\n",
    "print(f\"Tipo de dato de las etiquetas: {y_train.dtype}\")\n",
    "\n",
    "# Revisar las etiquetas únicas en el dataset\n",
    "unique_labels_train = np.unique(y_train)\n",
    "unique_labels_test = np.unique(y_test)\n",
    "print(f\"Etiquetas únicas en el conjunto de entrenamiento: {unique_labels_train}\")\n",
    "print(f\"Etiquetas únicas en el conjunto de prueba: {unique_labels_test}\")\n",
    "\n",
    "# Estadísticas básicas sobre los datos\n",
    "print(f\"Valor mínimo en las imágenes de entrenamiento: {np.min(x_train)}\")\n",
    "print(f\"Valor máximo en las imágenes de entrenamiento: {np.max(x_train)}\")\n",
    "print(f\"Valor promedio en las imágenes de entrenamiento: {np.mean(x_train)}\")\n",
    "\n",
    "# Ver una muestra del dataset (una imagen y su etiqueta)\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title(f\"Etiqueta: {y_train[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo después de la normalización: 0.0\n",
      "Valor máximo después de la normalización: 1.0\n",
      "Nuevo tamaño del conjunto de entrenamiento (aplanado): (60000, 784)\n",
      "Nuevo tamaño del conjunto de prueba (aplanado): (10000, 784)\n",
      "Nuevo formato de las etiquetas (one-hot): (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Paso 2: Procesos de limpieza o transformación de los datos\n",
    "\n",
    "# Normalizar las imágenes (de 0-255 a 0-1)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(f\"Valor mínimo después de la normalización: {np.min(x_train)}\")\n",
    "print(f\"Valor máximo después de la normalización: {np.max(x_train)}\")\n",
    "\n",
    "# Aplanar las imágenes (28x28 -> 784)\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "print(f\"Nuevo tamaño del conjunto de entrenamiento (aplanado): {x_train.shape}\")\n",
    "print(f\"Nuevo tamaño del conjunto de prueba (aplanado): {x_test.shape}\")\n",
    "\n",
    "# Convertir las etiquetas a formato categórico (one-hot encoding)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Nuevo formato de las etiquetas (one-hot): {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.5231 - loss: 1.3130 - val_accuracy: 0.7771 - val_loss: 0.5655\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7057 - loss: 0.8101 - val_accuracy: 0.7954 - val_loss: 0.5322\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7240 - loss: 0.7670 - val_accuracy: 0.3954 - val_loss: 1.6703\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.3462 - loss: 1.7898 - val_accuracy: 0.4890 - val_loss: 1.5431\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.3976 - loss: 1.6392 - val_accuracy: 0.4586 - val_loss: 1.5791\n",
      "Epoch 6/10\n",
      "\u001b[1m243/469\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.3693 - loss: 1.7297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 52\u001b[0m\n\u001b[1;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m create_dense_model(input_shape, num_classes, \n\u001b[1;32m     43\u001b[0m                            layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m], \n\u001b[1;32m     44\u001b[0m                            activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m                            loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     49\u001b[0m                            metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, \n\u001b[1;32m     53\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m     54\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \n\u001b[1;32m     55\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Paso 3: Crear y entrenar el modelo\n",
    "\n",
    "def create_dense_model(input_shape, num_classes, \n",
    "                       layers=[128, 64], \n",
    "                       activation='relu', \n",
    "                       dropout_rate=0.5, \n",
    "                       optimizer='adam', \n",
    "                       learning_rate=0.001, \n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'],\n",
    "                       initializer='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Primera capa oculta con la forma de entrada\n",
    "    model.add(Dense(layers[0], input_shape=(input_shape,), activation=activation, kernel_initializer=initializer))\n",
    "    \n",
    "    # Dropout opcional\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Capas intermedias ocultas\n",
    "    for units in layers[1:]:\n",
    "        model.add(Dense(units, activation=activation, kernel_initializer=initializer))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Capa de salida (softmax para clasificación multicategoría)\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer=initializer))\n",
    "    \n",
    "    # Configurar el optimizador\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Parámetros comunes del modelo\n",
    "input_shape = 28 * 28  # Tamaño de las imágenes aplanadas\n",
    "num_classes = 10       # 10 categorías de prendas\n",
    "\n",
    "# Early Stopping: detener si no mejora en 3 épocas consecutivas\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Diferentes configuraciones para probar, incluyendo inicializadores\n",
    "configurations = [\n",
    "    {'layers': [128, 64], 'activation': 'relu', 'dropout_rate': 0.5, 'optimizer': 'adam', 'learning_rate': 0.001, 'initializer': 'he_normal'},\n",
    "    {'layers': [256, 128, 64], 'activation': 'relu', 'dropout_rate': 0.3, 'optimizer': 'adam', 'learning_rate': 0.001, 'initializer': 'glorot_uniform'},\n",
    "    {'layers': [128, 64], 'activation': 'tanh', 'dropout_rate': 0.5, 'optimizer': 'sgd', 'learning_rate': 0.01, 'initializer': 'he_normal'},\n",
    "    {'layers': [512, 256], 'activation': 'relu', 'dropout_rate': 0.4, 'optimizer': 'adam', 'learning_rate': 0.0005, 'initializer': 'glorot_uniform'}\n",
    "]\n",
    "\n",
    "# Paso 3: Probar múltiples configuraciones\n",
    "for i, config in enumerate(configurations):\n",
    "    print(f\"\\nEntrenando modelo con configuración {i+1}: {config}\")\n",
    "    \n",
    "    # Crear el modelo con la configuración actual\n",
    "    model = create_dense_model(input_shape, num_classes, \n",
    "                               layers=config['layers'],\n",
    "                               activation=config['activation'], \n",
    "                               dropout_rate=config['dropout_rate'], \n",
    "                               optimizer=config['optimizer'], \n",
    "                               learning_rate=config['learning_rate'],\n",
    "                               loss='categorical_crossentropy',\n",
    "                               metrics=['accuracy'],\n",
    "                               initializer=config['initializer'])\n",
    "    \n",
    "    # Entrenar el modelo con Early Stopping\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        epochs=20, \n",
    "                        batch_size=128, \n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=1)\n",
    "    \n",
    "    # Paso 4: Graficar los resultados para cada configuración\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Gráfico de accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_df['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(history_df['val_accuracy'], label='Validación')\n",
    "    plt.title(f'Precisión (Accuracy) - Configuración {i+1}')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gráfico de pérdida (loss)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_df['loss'], label='Entrenamiento')\n",
    "    plt.plot(history_df['val_loss'], label='Validación')\n",
    "    plt.title(f'Pérdida (Loss) - Configuración {i+1}')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Mostrar los gráficos\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Accuracy (configuración {i+1}): {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Loss (configuración {i+1}): {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Evaluar el modelo\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Hacer predicciones en el conjunto de prueba\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Convertir las predicciones a labels (la clase con mayor probabilidad)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convertir los labels reales desde el one-hot encoding a valores enteros\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Diccionario para mapear los labels numéricos a sus categorías de prendas\n",
    "label_names = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "# Mapear las predicciones y los labels reales a sus nombres de categoría\n",
    "predicted_labels_names = [label_names[label] for label in predicted_labels]\n",
    "true_labels_names = [label_names[label] for label in true_labels]\n",
    "\n",
    "# Crear un DataFrame con los nombres de los labels reales y las predicciones\n",
    "results_df = pd.DataFrame({\n",
    "    'True Label': true_labels_names,\n",
    "    'Predicted Label': predicted_labels_names\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
